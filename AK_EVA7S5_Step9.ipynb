{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AK_EVA7S5_Step9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkankshaK-AI/S5Assignment/blob/main/AK_EVA7S5_Step9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5GVNo1WWeAk"
      },
      "source": [
        "# Adding image augmentation- image rotation to transforms step. No change will be done in the model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n",
        "\n",
        "Here is the list of all the transformations which come pre-built with PyTorch\n",
        "\n",
        "1.   Compose\n",
        "2.   ToTensor\n",
        "3.   ToPILImage\n",
        "4. Normalize\n",
        "5. Resize\n",
        "6. Scale\n",
        "7. CenterCrop\n",
        "8. Pad\n",
        "9. Lambda\n",
        "10. RandomApply\n",
        "11. RandomChoice\n",
        "12. RandomOrder\n",
        "13. RandomCrop\n",
        "14. RandomHorizontalFlip\n",
        "15. RandomVerticalFlip\n",
        "16. RandomResizedCrop\n",
        "17. RandomSizedCrop\n",
        "18. FiveCrop\n",
        "19. TenCrop\n",
        "20. LinearTransformation\n",
        "21. ColorJitter\n",
        "22. RandomRotation\n",
        "23. RandomAffine\n",
        "24. Grayscale\n",
        "25. RandomGrayscale\n",
        "26. RandomPerspective\n",
        "27. RandomErasing\n",
        "\n",
        "You can read more about them [here](https://pytorch.org/docs/stable/_modules/torchvision/transforms/transforms.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtssFUKb-jqx"
      },
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomRotation((-7.0,7.0), fill=(1,)), # adding image rotation only in train\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                      #  # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A84rlfDA23"
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8OLDR79DrHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7e7596-42e9-463a-d830-1d4f82c9f998"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFjoFekE_va"
      },
      "source": [
        "# Data Statistics\n",
        "\n",
        "It is important to know your data very well. Let's check some of the statistics around our data and how it actually looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWZPPo3yEHDW"
      },
      "source": [
        "# # We'd need to convert it into Numpy! Remember above we have converted it into tensors already\n",
        "# train_data = train.train_data\n",
        "# train_data = train.transform(train_data.numpy())\n",
        "\n",
        "# print('[Train]')\n",
        "# print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
        "# print(' - Tensor Shape:', train.train_data.size())\n",
        "# print(' - min:', torch.min(train_data))\n",
        "# print(' - max:', torch.max(train_data))\n",
        "# print(' - mean:', torch.mean(train_data))\n",
        "# print(' - std:', torch.std(train_data))\n",
        "# print(' - var:', torch.var(train_data))\n",
        "\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "\n",
        "# # Let's visualize some of the images\n",
        "# %matplotlib inline\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l9lNaWYKuik"
      },
      "source": [
        "## MORE\n",
        "\n",
        "It is important that we view as many images as possible. This is required to get some idea on image augmentation later on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXXAg8hbK16u"
      },
      "source": [
        "# figure = plt.figure()\n",
        "# num_of_images = 60\n",
        "# for index in range(1, num_of_images + 1):\n",
        "#     plt.subplot(6, 10, index)\n",
        "#     plt.axis('off')\n",
        "#     plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF5-8_I3G6ix"
      },
      "source": [
        "# How did we get those mean and std values which we used above?\n",
        "\n",
        "Let's run a small experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yooPHm_aFc5A"
      },
      "source": [
        "\n",
        "# simple_transforms = transforms.Compose([\n",
        "#                                       #  transforms.Resize((28, 28)),\n",
        "#                                       #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "#                                        transforms.ToTensor(),\n",
        "#                                       #  transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "#                                        # Note the difference between (0.1307) and (0.1307,)\n",
        "#                                        ])\n",
        "# exp = datasets.MNIST('./data', train=True, download=True, transform=simple_transforms)\n",
        "# exp_data = exp.train_data\n",
        "# exp_data = exp.transform(exp_data.numpy())\n",
        "\n",
        "# print('[Train]')\n",
        "# print(' - Numpy Shape:', exp.train_data.cpu().numpy().shape)\n",
        "# print(' - Tensor Shape:', exp.train_data.size())\n",
        "# print(' - min:', torch.min(exp_data))\n",
        "# print(' - max:', torch.max(exp_data))\n",
        "# print(' - mean:', torch.mean(exp_data))\n",
        "# print(' - std:', torch.std(exp_data))\n",
        "# print(' - var:', torch.var(exp_data))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h"
      },
      "source": [
        "# The model\n",
        "Reducing the number of parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FXQlB9kH1ov"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "dropout_value=0.1\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 26\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 24\n",
        "\n",
        "         # TRANSITION BLOCK 1 #here we are adding a conv layer and then pooling layer. This is faster\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),  # not added in transition block\n",
        "            # nn.ReLU(),  # not added in transition block\n",
        "            # nn.Dropout(dropout_value)  # not added in transition block\n",
        "        ) # output_size = 24\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 10\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) #output_size=1\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1,1), padding=0, bias=False),\n",
        "        ) # adding parameters after GAP layer\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo"
      },
      "source": [
        "# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is. \n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skB97zIJQQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9450e266-861a-41fe-d451-21bc97be1f49"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
            "              ReLU-3           [-1, 16, 26, 26]               0\n",
            "           Dropout-4           [-1, 16, 26, 26]               0\n",
            "            Conv2d-5           [-1, 32, 24, 24]           4,608\n",
            "       BatchNorm2d-6           [-1, 32, 24, 24]              64\n",
            "              ReLU-7           [-1, 32, 24, 24]               0\n",
            "           Dropout-8           [-1, 32, 24, 24]               0\n",
            "            Conv2d-9           [-1, 10, 24, 24]             320\n",
            "        MaxPool2d-10           [-1, 10, 12, 12]               0\n",
            "           Conv2d-11           [-1, 16, 10, 10]           1,440\n",
            "      BatchNorm2d-12           [-1, 16, 10, 10]              32\n",
            "             ReLU-13           [-1, 16, 10, 10]               0\n",
            "          Dropout-14           [-1, 16, 10, 10]               0\n",
            "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
            "      BatchNorm2d-16             [-1, 16, 8, 8]              32\n",
            "             ReLU-17             [-1, 16, 8, 8]               0\n",
            "          Dropout-18             [-1, 16, 8, 8]               0\n",
            "           Conv2d-19             [-1, 16, 6, 6]           2,304\n",
            "      BatchNorm2d-20             [-1, 16, 6, 6]              32\n",
            "             ReLU-21             [-1, 16, 6, 6]               0\n",
            "          Dropout-22             [-1, 16, 6, 6]               0\n",
            "           Conv2d-23             [-1, 16, 6, 6]           2,304\n",
            "      BatchNorm2d-24             [-1, 16, 6, 6]              32\n",
            "             ReLU-25             [-1, 16, 6, 6]               0\n",
            "          Dropout-26             [-1, 16, 6, 6]               0\n",
            "        AvgPool2d-27             [-1, 16, 1, 1]               0\n",
            "           Conv2d-28             [-1, 10, 1, 1]             160\n",
            "================================================================\n",
            "Total params: 13,808\n",
            "Trainable params: 13,808\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.06\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 1.12\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3"
      },
      "source": [
        "# Training and Testing\n",
        "\n",
        "\n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n",
        "\n",
        "Let's write train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkF2nN_LYIb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = [] # train accuracy\n",
        "test_acc = [] #test accuracy\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq"
      },
      "source": [
        "# Let's Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMCFxeAKOB53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fadda6-362f-43df-eaed-e990a929d3a8"
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 15\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Loss=0.20885634422302246 Batch_id=468 Accuracy=78.68: 100%|██████████| 469/469 [00:25<00:00, 18.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0735, Accuracy: 9833/10000 (98.33%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.03819292411208153 Batch_id=468 Accuracy=97.19: 100%|██████████| 469/469 [00:25<00:00, 18.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0758, Accuracy: 9777/10000 (97.77%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.05727000907063484 Batch_id=468 Accuracy=97.91: 100%|██████████| 469/469 [00:25<00:00, 18.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.13034160435199738 Batch_id=468 Accuracy=98.12: 100%|██████████| 469/469 [00:25<00:00, 18.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0317, Accuracy: 9903/10000 (99.03%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.06035899743437767 Batch_id=468 Accuracy=98.33: 100%|██████████| 469/469 [00:25<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0308, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.034079015254974365 Batch_id=468 Accuracy=98.48: 100%|██████████| 469/469 [00:25<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0271, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.10765077918767929 Batch_id=468 Accuracy=98.56: 100%|██████████| 469/469 [00:25<00:00, 18.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0248, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.03376177325844765 Batch_id=468 Accuracy=98.63: 100%|██████████| 469/469 [00:25<00:00, 18.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0286, Accuracy: 9909/10000 (99.09%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.018537435680627823 Batch_id=468 Accuracy=98.72: 100%|██████████| 469/469 [00:25<00:00, 18.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0251, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.05396546050906181 Batch_id=468 Accuracy=98.78: 100%|██████████| 469/469 [00:25<00:00, 18.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0221, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.06259393692016602 Batch_id=468 Accuracy=98.75: 100%|██████████| 469/469 [00:25<00:00, 18.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0254, Accuracy: 9911/10000 (99.11%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.05618922784924507 Batch_id=468 Accuracy=98.86: 100%|██████████| 469/469 [00:26<00:00, 17.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0222, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.020433252677321434 Batch_id=468 Accuracy=98.86: 100%|██████████| 469/469 [00:26<00:00, 17.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0233, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.017475411295890808 Batch_id=468 Accuracy=98.85: 100%|██████████| 469/469 [00:26<00:00, 17.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0240, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.06239929795265198 Batch_id=468 Accuracy=98.92: 100%|██████████| 469/469 [00:26<00:00, 17.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0196, Accuracy: 9944/10000 (99.44%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odozjbIvY12p"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}